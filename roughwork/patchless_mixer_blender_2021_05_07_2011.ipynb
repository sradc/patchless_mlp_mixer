{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of patchless_mixer_crusher_2021-05-07-2011.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRpOnzUMOLpE"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkEE7_qO6kRr",
        "outputId": "47d9ef1c-89cd-44bc-f614-166af175d797"
      },
      "source": [
        "x = np.random.random([10, 1, 2, 3])\n",
        "W = np.random.random([4, 3, 1])\n",
        "y = np.matmul(x, W)\n",
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 4, 2, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 294
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvtfS7A8XF9J"
      },
      "source": [
        "class BatchDense(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, num_neurons, activation):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.num_neurons = num_neurons\n",
        "        self.activation = activation if activation else lambda x: x\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.w = self.add_weight(shape=(self.num_layers, input_shape[-1], self.num_neurons),\n",
        "                               initializer='he_uniform',\n",
        "                               trainable=True)\n",
        "        self.b = self.add_weight(shape=(self.num_layers, 1, self.num_neurons),\n",
        "                               initializer='zeros',\n",
        "                               trainable=True)\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        return self.activation(tf.matmul(inputs, self.w) + self.b)\n",
        "\n",
        "class MixerMLP(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, outsize, hiddensize=None):\n",
        "        super().__init__()\n",
        "        hiddensize = hiddensize if hiddensize else outsize\n",
        "        self.layer_1 = BatchDense(num_layers, hiddensize, tf.nn.gelu)\n",
        "        self.layer_2 = BatchDense(num_layers, outsize, None)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        h = self.layer_1(inputs)\n",
        "        return self.layer_2(h)\n",
        "\n",
        "class Mixer(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, outheight, outwidth):\n",
        "        super().__init__()\n",
        "        self.layer_1 = MixerMLP(num_layers, outheight)\n",
        "        self.layer_2 = MixerMLP(num_layers, outwidth)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        h = tf.keras.layers.Permute((1, 3, 2))(inputs)\n",
        "        h = self.layer_1(h)\n",
        "        h = tf.keras.layers.Permute((1, 3, 2))(h)\n",
        "        return self.layer_2(h)\n",
        "\n",
        "class ZeroFilter(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.a = tf.Variable(0.0, trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.a * inputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGAaO3H6S8uF"
      },
      "source": [
        "def resnet_mixer(height, width, depth, num_classes, n_repeat, name=None):\n",
        "    inputs = tf.keras.layers.Input(shape=(height, width))\n",
        "    expanded = tf.keras.layers.Reshape((1, height, width))(inputs)    \n",
        "    h = expanded\n",
        "\n",
        "    for i in range(n_repeat):\n",
        "        h = ZeroFilter()(Mixer(depth, height, width)(h)) + h\n",
        "    \n",
        "    rows_out = MixerMLP(depth, 1)(h)\n",
        "    rows_out = tf.keras.layers.Lambda(lambda x: x[:, :, :, 0])(rows_out)\n",
        "\n",
        "    cols_out = tf.keras.layers.Permute((1, 3, 2))(h)\n",
        "    cols_out = MixerMLP(depth, 1)(cols_out)\n",
        "    cols_out = tf.keras.layers.Lambda(lambda x: x[:, :, :, 0])(cols_out)\n",
        "\n",
        "    concat = tf.keras.layers.Concatenate()([rows_out, cols_out])\n",
        "    av = tf.keras.layers.Lambda(lambda x: tf.reduce_mean(x, axis=1))(concat)  # average depthwise\n",
        "    flat = tf.keras.layers.Flatten()(av)\n",
        "    y = tf.keras.layers.Dense(num_classes)(flat)\n",
        "    return tf.keras.Model(inputs=inputs, outputs=y, name=name)\n",
        "\n",
        "\n",
        "def repeated_patchless_mixer_2(height, width, hidden_dim, size, num_classes, n_repeat, name=None):\n",
        "    inputs = tf.keras.layers.Input(shape=(height, width))\n",
        "    expanded = tf.keras.layers.Reshape((1, height, width))(inputs)    \n",
        "    h = Mixer(size, hidden_dim, hidden_dim)(expanded)\n",
        "\n",
        "    for i in range(n_repeat):\n",
        "        h = ZeroFilter()(Mixer(size, hidden_dim, hidden_dim)(h)) + h\n",
        "    \n",
        "    rows_out = MixerMLP(size, 1)(h)\n",
        "    rows_out = tf.keras.layers.Lambda(lambda x: x[:, :, :, 0])(rows_out)\n",
        "\n",
        "    cols_out = tf.keras.layers.Permute((1, 3, 2))(h)\n",
        "    cols_out = MixerMLP(size, 1)(cols_out)\n",
        "    cols_out = tf.keras.layers.Lambda(lambda x: x[:, :, :, 0])(cols_out)\n",
        "\n",
        "    concat = tf.keras.layers.Concatenate()([rows_out, cols_out])\n",
        "    flat = tf.keras.layers.Flatten()(concat)\n",
        "    y = tf.keras.layers.Dense(num_classes)(flat)\n",
        "    return tf.keras.Model(inputs=inputs, outputs=y, name=name)\n",
        "\n",
        "\n",
        "def repeated_patchless_mixer(height, width, hidden_dim, size, num_classes, n_repeat, name=None):\n",
        "    \"Closer to original, with averaged layer.\"\n",
        "    inputs = tf.keras.layers.Input(shape=(height, width))\n",
        "    expanded = tf.keras.layers.Reshape((1, height, width))(inputs)\n",
        "    row_wise = MixerMLP(size, hidden_dim)(expanded)\n",
        "    transposed = tf.keras.layers.Permute((1, 3, 2))(row_wise)\n",
        "    col_wise = MixerMLP(size, hidden_dim)(transposed)\n",
        "    h_ = col_wise\n",
        "    for i in range(n_repeat):\n",
        "        h = tf.keras.layers.Permute((1, 3, 2))(h_)\n",
        "        h = MixerMLP(size, hidden_dim)(h)\n",
        "        h = tf.keras.layers.Permute((1, 3, 2))(h)\n",
        "        h = MixerMLP(size, hidden_dim)(h)\n",
        "        h_ = h + h_\n",
        "    averaged = tf.keras.layers.Lambda(lambda x: tf.reduce_mean(x, axis=1))(col_wise)\n",
        "    flat = tf.keras.layers.Flatten()(h_)\n",
        "    y = tf.keras.layers.Dense(num_classes)(flat)\n",
        "    return tf.keras.Model(inputs=inputs, outputs=y, name=name)\n",
        "\n",
        "def patchless_mixer(height, width, hidden_dim, depth, num_classes, name=None):\n",
        "    inputs = tf.keras.layers.Input(shape=(height, width))\n",
        "    expanded = tf.keras.layers.Reshape((1, height, width))(inputs)\n",
        "    row_wise = MixerMLP(depth, hidden_dim)(expanded)\n",
        "    transposed = tf.keras.layers.Permute((1, 3, 2))(row_wise)\n",
        "    col_wise = MixerMLP(depth, hidden_dim)(transposed)\n",
        "    averaged = tf.keras.layers.Lambda(lambda x: tf.reduce_mean(x, axis=1))(col_wise)\n",
        "    flat = tf.keras.layers.Flatten()(averaged)\n",
        "    y = tf.keras.layers.Dense(num_classes)(flat)\n",
        "    return tf.keras.Model(inputs=inputs, outputs=y, name=name)\n",
        "\n",
        "def blender(height, width, size, num_classes, name=None):\n",
        "    inputs = tf.keras.layers.Input(shape=(height, width))\n",
        "    expanded = tf.keras.layers.Reshape((1, height, width))(inputs)\n",
        "    row_wise = BatchDense(size, 1)(expanded)\n",
        "    transposed = tf.keras.layers.Permute((1, 3, 2))(row_wise)\n",
        "    col_wise = BatchDense(size, 1)(transposed)\n",
        "    flattened = tf.keras.layers.Flatten()(col_wise)\n",
        "    y = tf.keras.layers.Dense(num_classes)(flattened)\n",
        "    return tf.keras.Model(inputs=inputs, outputs=y, name=name)\n",
        "\n",
        "def wider_blender(height, width, hiddensize, size, num_classes, name=None):\n",
        "    inputs = tf.keras.layers.Input(shape=(height, width))\n",
        "    expanded = tf.keras.layers.Reshape((1, height, width))(inputs)\n",
        "    row_wise = MixerMLP(size, hiddensize, 1)(expanded)\n",
        "    transposed = tf.keras.layers.Permute((1, 3, 2))(row_wise)\n",
        "    col_wise = MixerMLP(size, hiddensize, 1)(transposed)\n",
        "    flattened = tf.keras.layers.Flatten()(col_wise)\n",
        "    y = tf.keras.layers.Dense(num_classes)(flattened)\n",
        "    return tf.keras.Model(inputs=inputs, outputs=y, name=name)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIP_iuB4hl-6"
      },
      "source": [
        "# MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23Lh1G8ox1If"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "train_images, test_images = train_images.astype(np.float32), test_images.astype(np.float32)\n",
        "train_images, test_images = tf.constant(train_images), tf.constant(test_images)\n",
        "\n",
        "height, width = train_images.shape[-2:]\n",
        "num_classes = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5DoWadl7_uA",
        "outputId": "cbe24de8-9ef1-4b59-f842-6101be4213ab"
      },
      "source": [
        "\"RESNET MIXER\"\n",
        "hidden_dim = 64\n",
        "n_repeat = 2\n",
        "depth = 16\n",
        "model = resnet_mixer(height, width, depth, num_classes, n_repeat)\n",
        "print(model.summary())\n",
        "model.predict(train_images[:2, :, :])\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(train_images, train_labels, batch_size=64, epochs=10, \n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_165\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_196 (InputLayer)          [(None, 28, 28)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_184 (Reshape)           (None, 1, 28, 28)    0           input_196[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "mixer_12 (Mixer)                (None, 16, 28, 28)   51968       reshape_184[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "zero_filter_6 (ZeroFilter)      (None, 16, 28, 28)   1           mixer_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_176 (TFOpL (None, 16, 28, 28)   0           zero_filter_6[0][0]              \n",
            "                                                                 reshape_184[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "mixer_13 (Mixer)                (None, 16, 28, 28)   51968       tf.__operators__.add_176[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "zero_filter_7 (ZeroFilter)      (None, 16, 28, 28)   1           mixer_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_177 (TFOpL (None, 16, 28, 28)   0           zero_filter_7[0][0]              \n",
            "                                                                 tf.__operators__.add_176[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "permute_454 (Permute)           (None, 16, 28, 28)   0           tf.__operators__.add_177[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "mixer_mlp_455 (MixerMLP)        (None, 16, 28, 1)    496         tf.__operators__.add_177[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "mixer_mlp_456 (MixerMLP)        (None, 16, 28, 1)    496         permute_454[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_79 (Lambda)              (None, 16, 28)       0           mixer_mlp_455[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_80 (Lambda)              (None, 16, 28)       0           mixer_mlp_456[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 16, 56)       0           lambda_79[0][0]                  \n",
            "                                                                 lambda_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_117 (Flatten)           (None, 896)          0           concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_201 (Dense)               (None, 10)           8970        flatten_117[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 113,900\n",
            "Trainable params: 113,900\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f56c1ce53b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/10\n",
            "938/938 [==============================] - 10s 9ms/step - loss: 0.9061 - accuracy: 0.7638 - val_loss: 0.1510 - val_accuracy: 0.9552\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.1412 - accuracy: 0.9592 - val_loss: 0.0978 - val_accuracy: 0.9690\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.0875 - accuracy: 0.9733 - val_loss: 0.0717 - val_accuracy: 0.9774\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.0602 - accuracy: 0.9810 - val_loss: 0.0644 - val_accuracy: 0.9795\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.0495 - accuracy: 0.9845 - val_loss: 0.0573 - val_accuracy: 0.9821\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.0394 - accuracy: 0.9880 - val_loss: 0.0531 - val_accuracy: 0.9836\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.0322 - accuracy: 0.9898 - val_loss: 0.0524 - val_accuracy: 0.9836\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.0267 - accuracy: 0.9916 - val_loss: 0.0635 - val_accuracy: 0.9816\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.0210 - accuracy: 0.9934 - val_loss: 0.0520 - val_accuracy: 0.9852\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.0185 - accuracy: 0.9938 - val_loss: 0.0578 - val_accuracy: 0.9834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "falD5raIvKKk",
        "outputId": "5ccd9efc-e4f2-4324-b0f2-ca795ff03dae"
      },
      "source": [
        "\"DEEPER REPEATED PATCHLESS MIXER ROW-COL CLASSIFICATION\"\n",
        "num_classes = 10\n",
        "hidden_dim = 64\n",
        "n_repeat = 2\n",
        "depth = 8\n",
        "model = repeated_patchless_mixer_2(height, width, hidden_dim, depth, num_classes, n_repeat)\n",
        "print(model.summary())\n",
        "model.predict(train_images[:2, :, :])\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(train_images, train_labels, batch_size=64, epochs=10, \n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_163\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_194 (InputLayer)          [(None, 28, 28)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_182 (Reshape)           (None, 1, 28, 28)    0           input_194[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "mixer_mlp_437 (MixerMLP)        (None, 8, 28, 64)    48128       reshape_182[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "permute_451 (Permute)           (None, 8, 64, 28)    0           mixer_mlp_437[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixer_mlp_438 (MixerMLP)        (None, 8, 64, 64)    48128       permute_451[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "mixer_8 (Mixer)                 (None, 8, 64, 64)    133120      mixer_mlp_438[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "zero_filter_2 (ZeroFilter)      (None, 8, 64, 64)    1           mixer_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_172 (TFOpL (None, 8, 64, 64)    0           zero_filter_2[0][0]              \n",
            "                                                                 mixer_mlp_438[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixer_9 (Mixer)                 (None, 8, 64, 64)    133120      tf.__operators__.add_172[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "zero_filter_3 (ZeroFilter)      (None, 8, 64, 64)    1           mixer_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_173 (TFOpL (None, 8, 64, 64)    0           zero_filter_3[0][0]              \n",
            "                                                                 tf.__operators__.add_172[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "permute_452 (Permute)           (None, 8, 64, 64)    0           tf.__operators__.add_173[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "mixer_mlp_443 (MixerMLP)        (None, 8, 64, 1)     536         tf.__operators__.add_173[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "mixer_mlp_444 (MixerMLP)        (None, 8, 64, 1)     536         permute_452[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_75 (Lambda)              (None, 8, 64)        0           mixer_mlp_443[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_76 (Lambda)              (None, 8, 64)        0           mixer_mlp_444[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 8, 128)       0           lambda_75[0][0]                  \n",
            "                                                                 lambda_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_115 (Flatten)           (None, 1024)         0           concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_199 (Dense)               (None, 10)           10250       flatten_115[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 373,820\n",
            "Trainable params: 373,820\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f574c4650e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/10\n",
            "938/938 [==============================] - 16s 14ms/step - loss: 0.6421 - accuracy: 0.8026 - val_loss: 0.1404 - val_accuracy: 0.9559\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.1150 - accuracy: 0.9667 - val_loss: 0.0810 - val_accuracy: 0.9746\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.0778 - accuracy: 0.9757 - val_loss: 0.0749 - val_accuracy: 0.9768\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.0592 - accuracy: 0.9804 - val_loss: 0.0671 - val_accuracy: 0.9795\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.0484 - accuracy: 0.9850 - val_loss: 0.0624 - val_accuracy: 0.9791\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.0406 - accuracy: 0.9874 - val_loss: 0.0606 - val_accuracy: 0.9811\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.0337 - accuracy: 0.9894 - val_loss: 0.0540 - val_accuracy: 0.9828\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.0277 - accuracy: 0.9905 - val_loss: 0.0586 - val_accuracy: 0.9812\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.0241 - accuracy: 0.9917 - val_loss: 0.0619 - val_accuracy: 0.9824\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.0194 - accuracy: 0.9937 - val_loss: 0.0665 - val_accuracy: 0.9823\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bmY-VaRpMbm"
      },
      "source": [
        "\"DEEPER REPEATED PATCHLESS MIXER\"\n",
        "num_classes = 10\n",
        "hidden_dim = 28\n",
        "n_repeat = 3\n",
        "depth = 8\n",
        "model = repeated_patchless_mixer(height, width, hidden_dim, depth, num_classes, n_repeat)\n",
        "print(model.summary())\n",
        "model.predict(train_images[:2, :, :])\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(train_images, train_labels, batch_size=64, epochs=10, \n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsRlfDmckhHm",
        "outputId": "358052c8-c6f9-4633-fb2a-9a1c4a63b00c"
      },
      "source": [
        "\"REPEATED PATCHLESS MIXER\"  # todo allow multichannel\n",
        "num_classes = 10\n",
        "hidden_dim = 28\n",
        "n_repeat = 3\n",
        "depth = 1\n",
        "model = repeated_patchless_mixer(height, width, hidden_dim, depth, num_classes, n_repeat)\n",
        "print(model.summary())\n",
        "model.predict(train_images[:2, :, :])\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(train_images, train_labels, batch_size=64, epochs=10, \n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_126\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_152 (InputLayer)          [(None, 28, 28)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_140 (Reshape)           (None, 1, 28, 28)    0           input_152[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "mixer_mlp_40 (MixerMLP)         (None, 1, 28, 32)    1984        reshape_140[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "permute_109 (Permute)           (None, 1, 32, 28)    0           mixer_mlp_40[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixer_mlp_41 (MixerMLP)         (None, 1, 32, 32)    1984        permute_109[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "permute_110 (Permute)           (None, 1, 32, 32)    0           mixer_mlp_41[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixer_mlp_42 (MixerMLP)         (None, 1, 32, 32)    2112        permute_110[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "permute_111 (Permute)           (None, 1, 32, 32)    0           mixer_mlp_42[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixer_mlp_43 (MixerMLP)         (None, 1, 32, 32)    2112        permute_111[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_15 (TFOpLa (None, 1, 32, 32)    0           mixer_mlp_43[0][0]               \n",
            "                                                                 mixer_mlp_41[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute_112 (Permute)           (None, 1, 32, 32)    0           tf.__operators__.add_15[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixer_mlp_44 (MixerMLP)         (None, 1, 32, 32)    2112        permute_112[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "permute_113 (Permute)           (None, 1, 32, 32)    0           mixer_mlp_44[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixer_mlp_45 (MixerMLP)         (None, 1, 32, 32)    2112        permute_113[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_16 (TFOpLa (None, 1, 32, 32)    0           mixer_mlp_45[0][0]               \n",
            "                                                                 tf.__operators__.add_15[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "permute_114 (Permute)           (None, 1, 32, 32)    0           tf.__operators__.add_16[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixer_mlp_46 (MixerMLP)         (None, 1, 32, 32)    2112        permute_114[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "permute_115 (Permute)           (None, 1, 32, 32)    0           mixer_mlp_46[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixer_mlp_47 (MixerMLP)         (None, 1, 32, 32)    2112        permute_115[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_17 (TFOpLa (None, 1, 32, 32)    0           mixer_mlp_47[0][0]               \n",
            "                                                                 tf.__operators__.add_16[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_91 (Flatten)            (None, 1024)         0           tf.__operators__.add_17[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dense_175 (Dense)               (None, 10)           10250       flatten_91[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 26,890\n",
            "Trainable params: 26,890\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f56c1b86290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/10\n",
            "938/938 [==============================] - 6s 5ms/step - loss: 0.7084 - accuracy: 0.8015 - val_loss: 0.1605 - val_accuracy: 0.9513\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.1333 - accuracy: 0.9589 - val_loss: 0.1202 - val_accuracy: 0.9646\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0893 - accuracy: 0.9724 - val_loss: 0.0994 - val_accuracy: 0.9711\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0711 - accuracy: 0.9777 - val_loss: 0.1015 - val_accuracy: 0.9707\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0563 - accuracy: 0.9811 - val_loss: 0.0830 - val_accuracy: 0.9754\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0473 - accuracy: 0.9850 - val_loss: 0.1069 - val_accuracy: 0.9700\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0408 - accuracy: 0.9865 - val_loss: 0.0961 - val_accuracy: 0.9733\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0335 - accuracy: 0.9889 - val_loss: 0.0949 - val_accuracy: 0.9747\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0306 - accuracy: 0.9902 - val_loss: 0.1054 - val_accuracy: 0.9741\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0330 - accuracy: 0.9891 - val_loss: 0.0879 - val_accuracy: 0.9785\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBNZqGMqhuoO",
        "outputId": "b3a83a6e-1946-417e-ed5a-e5c833cca431"
      },
      "source": [
        "\"PATCHLESS MIXER\"\n",
        "num_classes = 10\n",
        "hidden_dim = 28\n",
        "depth = 32\n",
        "model = patchless_mixer(height, width, hidden_dim, depth, num_classes)\n",
        "print(model.summary())\n",
        "model.predict(train_images[:2, :, :])\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(train_images, train_labels, batch_size=64, epochs=10, \n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_124\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_149 (InputLayer)       [(None, 28, 28)]          0         \n",
            "_________________________________________________________________\n",
            "reshape_138 (Reshape)        (None, 1, 28, 28)         0         \n",
            "_________________________________________________________________\n",
            "mixer_mlp_38 (MixerMLP)      (None, 32, 28, 32)        63488     \n",
            "_________________________________________________________________\n",
            "permute_101 (Permute)        (None, 32, 32, 28)        0         \n",
            "_________________________________________________________________\n",
            "mixer_mlp_39 (MixerMLP)      (None, 32, 32, 32)        63488     \n",
            "_________________________________________________________________\n",
            "lambda_37 (Lambda)           (None, 32, 32)            0         \n",
            "_________________________________________________________________\n",
            "flatten_89 (Flatten)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_157 (Dense)            (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 137,226\n",
            "Trainable params: 137,226\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f56befe7f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/10\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.9367 - accuracy: 0.6836 - val_loss: 0.1433 - val_accuracy: 0.9590\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.1382 - accuracy: 0.9585 - val_loss: 0.0984 - val_accuracy: 0.9685\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0898 - accuracy: 0.9724 - val_loss: 0.0806 - val_accuracy: 0.9734\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0726 - accuracy: 0.9781 - val_loss: 0.0665 - val_accuracy: 0.9795\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0591 - accuracy: 0.9822 - val_loss: 0.0690 - val_accuracy: 0.9789\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0522 - accuracy: 0.9832 - val_loss: 0.0666 - val_accuracy: 0.9776\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0439 - accuracy: 0.9857 - val_loss: 0.0610 - val_accuracy: 0.9805\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0409 - accuracy: 0.9869 - val_loss: 0.0563 - val_accuracy: 0.9820\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0315 - accuracy: 0.9896 - val_loss: 0.0579 - val_accuracy: 0.9816\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.0289 - accuracy: 0.9907 - val_loss: 0.0628 - val_accuracy: 0.9803\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c23sMyabUti",
        "outputId": "c0c96cb4-b805-4aa3-a437-1ceb2fb7c00a"
      },
      "source": [
        "\"BLENDER\"\n",
        "num_classes = 10\n",
        "size = 256\n",
        "model = blender(height, width, size, num_classes)\n",
        "print(model.summary())\n",
        "model.predict(train_images[:2, :, :])\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(train_images, train_labels, batch_size=64, epochs=10, \n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_105\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_128 (InputLayer)       [(None, 28, 28)]          0         \n",
            "_________________________________________________________________\n",
            "reshape_122 (Reshape)        (None, 1, 28, 28)         0         \n",
            "_________________________________________________________________\n",
            "batch_dense_30 (BatchDense)  (None, 256, 28, 1)        7424      \n",
            "_________________________________________________________________\n",
            "permute_58 (Permute)         (None, 256, 1, 28)        0         \n",
            "_________________________________________________________________\n",
            "batch_dense_31 (BatchDense)  (None, 256, 1, 1)         7424      \n",
            "_________________________________________________________________\n",
            "flatten_70 (Flatten)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_71 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 17,418\n",
            "Trainable params: 17,418\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f57a01d6dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/10\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.8553 - accuracy: 0.7810 - val_loss: 0.2884 - val_accuracy: 0.9146\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.2957 - accuracy: 0.9165 - val_loss: 0.2873 - val_accuracy: 0.9177\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.2878 - accuracy: 0.9198 - val_loss: 0.2742 - val_accuracy: 0.9195\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.2766 - accuracy: 0.9208 - val_loss: 0.2739 - val_accuracy: 0.9215\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.2745 - accuracy: 0.9211 - val_loss: 0.2670 - val_accuracy: 0.9233\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.2692 - accuracy: 0.9256 - val_loss: 0.2694 - val_accuracy: 0.9248\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.2651 - accuracy: 0.9262 - val_loss: 0.2676 - val_accuracy: 0.9236\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.2717 - accuracy: 0.9250 - val_loss: 0.2665 - val_accuracy: 0.9227\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.2683 - accuracy: 0.9244 - val_loss: 0.2646 - val_accuracy: 0.9243\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.2617 - accuracy: 0.9258 - val_loss: 0.2719 - val_accuracy: 0.9216\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5jTiGf4dpS-",
        "outputId": "f00bbdf3-1dcf-45ec-9f3a-6da4347f9085"
      },
      "source": [
        "\"WIDER BLENDER\"\n",
        "num_classes = 10\n",
        "size = 64\n",
        "hidden_size = 64\n",
        "model = wider_blender(height, width, hidden_size, size, num_classes)\n",
        "print(model.summary())\n",
        "model.predict(train_images[:2, :, :])\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(train_images, train_labels, batch_size=64, epochs=10, \n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_114\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_137 (InputLayer)       [(None, 28, 28)]          0         \n",
            "_________________________________________________________________\n",
            "reshape_131 (Reshape)        (None, 1, 28, 28)         0         \n",
            "_________________________________________________________________\n",
            "mixer_mlp_26 (MixerMLP)      (None, 64, 28, 1)         122944    \n",
            "_________________________________________________________________\n",
            "permute_67 (Permute)         (None, 64, 1, 28)         0         \n",
            "_________________________________________________________________\n",
            "mixer_mlp_27 (MixerMLP)      (None, 64, 1, 1)          122944    \n",
            "_________________________________________________________________\n",
            "flatten_79 (Flatten)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_81 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 246,538\n",
            "Trainable params: 246,538\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f56befe7950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.7587 - accuracy: 0.7645 - val_loss: 0.1592 - val_accuracy: 0.9537\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.1433 - accuracy: 0.9568 - val_loss: 0.1074 - val_accuracy: 0.9666\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.0973 - accuracy: 0.9709 - val_loss: 0.0904 - val_accuracy: 0.9745\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.0753 - accuracy: 0.9765 - val_loss: 0.0876 - val_accuracy: 0.9751\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.0642 - accuracy: 0.9804 - val_loss: 0.0905 - val_accuracy: 0.9732\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.0548 - accuracy: 0.9830 - val_loss: 0.0822 - val_accuracy: 0.9742\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.0442 - accuracy: 0.9862 - val_loss: 0.0804 - val_accuracy: 0.9775\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.0404 - accuracy: 0.9871 - val_loss: 0.0755 - val_accuracy: 0.9779\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.0347 - accuracy: 0.9887 - val_loss: 0.0773 - val_accuracy: 0.9784\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.0307 - accuracy: 0.9894 - val_loss: 0.0789 - val_accuracy: 0.9770\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "R4-AasyVec4E",
        "outputId": "f2b8fd24-f263-49e8-86c6-198b170d9d89"
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([.8, 1])\n",
        "plt.legend(loc='lower right')\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 1s - loss: 0.0628 - accuracy: 0.9803\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Si9BOGiwaaw"
      },
      "source": [
        "# CIFAR-10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8bFy7GfjG-D"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "train_images, test_images = train_images.astype(np.float32), test_images.astype(np.float32)\n",
        "height, width = 32, 32\n",
        "num_classes = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQDzCHpK81lk",
        "outputId": "2a8fd00b-6618-4d56-db34-ad23da13352e"
      },
      "source": [
        "\"RESNET MIXER\"\n",
        "n_repeat = 4\n",
        "depth = 16\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(height, width, channels))\n",
        "reshaped = tf.keras.layers.Reshape([height, width * channels])(inputs)\n",
        "model = resnet_mixer(height, width * channels, depth, num_classes, n_repeat)(reshaped)\n",
        "model = tf.keras.Model(inputs=inputs, outputs=model)\n",
        "\n",
        "print(model.summary())\n",
        "model.predict(train_images[:2, :, :])\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(train_images, train_labels, batch_size=64, epochs=10, \n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_169\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_201 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "reshape_189 (Reshape)        (None, 32, 96)            0         \n",
            "_________________________________________________________________\n",
            "model_168 (Functional)       (None, 10)                1349742   \n",
            "=================================================================\n",
            "Total params: 1,349,742\n",
            "Trainable params: 1,349,742\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f57437b7200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 28s 33ms/step - loss: 1.9549 - accuracy: 0.3012 - val_loss: 1.5427 - val_accuracy: 0.4564\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.4790 - accuracy: 0.4758 - val_loss: 1.3675 - val_accuracy: 0.5067\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.3239 - accuracy: 0.5266 - val_loss: 1.2893 - val_accuracy: 0.5407\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.2346 - accuracy: 0.5584 - val_loss: 1.2501 - val_accuracy: 0.5545\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.1628 - accuracy: 0.5890 - val_loss: 1.2112 - val_accuracy: 0.5726\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.0997 - accuracy: 0.6083 - val_loss: 1.1893 - val_accuracy: 0.5778\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.0385 - accuracy: 0.6316 - val_loss: 1.1862 - val_accuracy: 0.5862\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.9864 - accuracy: 0.6522 - val_loss: 1.1535 - val_accuracy: 0.5936\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.9211 - accuracy: 0.6773 - val_loss: 1.1616 - val_accuracy: 0.5980\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.8643 - accuracy: 0.6938 - val_loss: 1.1853 - val_accuracy: 0.5911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIXhw3-5-8Bf",
        "outputId": "8ea84eb1-34d6-44f3-b9c0-1b617e235cab"
      },
      "source": [
        "\"RESNET MIXER\"\n",
        "n_repeat = 16\n",
        "depth = 1\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(height, width, channels))\n",
        "reshaped = tf.keras.layers.Reshape([height, width * channels])(inputs)\n",
        "model = resnet_mixer(height, width * channels, depth, num_classes, n_repeat)(reshaped)\n",
        "model = tf.keras.Model(inputs=inputs, outputs=model)\n",
        "\n",
        "print(model.summary())\n",
        "model.predict(train_images[:2, :, :])\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(train_images, train_labels, batch_size=64, epochs=10, \n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_183\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_217 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "reshape_205 (Reshape)        (None, 32, 96)            0         \n",
            "_________________________________________________________________\n",
            "model_182 (Functional)       (None, 10)                333216    \n",
            "=================================================================\n",
            "Total params: 333,216\n",
            "Trainable params: 333,216\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f574ccfb170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 20s 16ms/step - loss: 1.8379 - accuracy: 0.3303 - val_loss: 1.3806 - val_accuracy: 0.5074\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 12s 15ms/step - loss: 1.3012 - accuracy: 0.5378 - val_loss: 1.2553 - val_accuracy: 0.5508\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 11s 15ms/step - loss: 1.1318 - accuracy: 0.5994 - val_loss: 1.1825 - val_accuracy: 0.5731\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 11s 15ms/step - loss: 0.9807 - accuracy: 0.6520 - val_loss: 1.1517 - val_accuracy: 0.5874\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 11s 15ms/step - loss: 0.8503 - accuracy: 0.6998 - val_loss: 1.2051 - val_accuracy: 0.5834\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 11s 15ms/step - loss: 0.6984 - accuracy: 0.7544 - val_loss: 1.2282 - val_accuracy: 0.5877\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 11s 15ms/step - loss: 0.5571 - accuracy: 0.8023 - val_loss: 1.3305 - val_accuracy: 0.5860\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 11s 15ms/step - loss: 0.4312 - accuracy: 0.8493 - val_loss: 1.5699 - val_accuracy: 0.5737\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 11s 15ms/step - loss: 0.3385 - accuracy: 0.8852 - val_loss: 1.7307 - val_accuracy: 0.5691\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 11s 15ms/step - loss: 0.2725 - accuracy: 0.9044 - val_loss: 1.9005 - val_accuracy: 0.5615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "p9VhhmZ-wcnd",
        "outputId": "59735e2d-9a4c-428b-b3b7-6aa56666b20b"
      },
      "source": [
        "\"DEEPER REPEATED PATCHLESS MIXER ROW-COL CLASSIFICATION\"\n",
        "num_classes = 10\n",
        "hidden_dim = 64\n",
        "n_repeat = 16\n",
        "depth = 8\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(height, width, channels))\n",
        "reshaped = tf.keras.layers.Reshape([height, width * channels])(inputs)\n",
        "model = repeated_patchless_mixer_2(height, width * channels, hidden_dim, depth, num_classes, n_repeat)(reshaped)\n",
        "model = tf.keras.Model(inputs=inputs, outputs=model)\n",
        "\n",
        "print(model.summary())\n",
        "model.predict(train_images[:2, :, :])\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(train_images, train_labels, batch_size=64, epochs=10, \n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_157\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_184 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "reshape_172 (Reshape)        (None, 32, 96)            0         \n",
            "_________________________________________________________________\n",
            "model_156 (Functional)       (None, 10)                2274362   \n",
            "=================================================================\n",
            "Total params: 2,274,362\n",
            "Trainable params: 2,274,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f574cf30d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/10\n",
            "219/782 [=======>......................] - ETA: 36s - loss: 2.1462 - accuracy: 0.1967"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-259-c56760502b54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m     17\u001b[0m history = model.fit(train_images, train_labels, batch_size=64, epochs=10, \n\u001b[0;32m---> 18\u001b[0;31m                     validation_data=(test_images, test_labels))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRuUEP1_pmoE",
        "outputId": "a4fddc96-c587-4029-b0d3-025d972a46e6"
      },
      "source": [
        "\"DEEPER REPEATED PATCHLESS MIXER\"\n",
        "num_classes = 10\n",
        "hidden_dim = 32\n",
        "n_repeat = 3\n",
        "depth = 8\n",
        "inputs = tf.keras.layers.Input(shape=(height, width, channels))\n",
        "reshaped = tf.keras.layers.Reshape([height, width * channels])(inputs)\n",
        "model = repeated_patchless_mixer(height, width * channels, hidden_dim, depth, num_classes, n_repeat)(reshaped)\n",
        "model = tf.keras.Model(inputs=inputs, outputs=model)\n",
        "print(model.summary())\n",
        "model.predict(train_images[:2, :, :])\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(train_images, train_labels, batch_size=64, epochs=10, \n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_130\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_156 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "reshape_144 (Reshape)        (None, 32, 96)            0         \n",
            "_________________________________________________________________\n",
            "model_129 (Functional)       (None, 10)                233482    \n",
            "=================================================================\n",
            "Total params: 233,482\n",
            "Trainable params: 233,482\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f574aa468c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 9s 9ms/step - loss: 1.9038 - accuracy: 0.3210 - val_loss: 1.5143 - val_accuracy: 0.4565\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.4937 - accuracy: 0.4722 - val_loss: 1.3783 - val_accuracy: 0.5032\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.3583 - accuracy: 0.5194 - val_loss: 1.2883 - val_accuracy: 0.5432\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.2599 - accuracy: 0.5567 - val_loss: 1.2676 - val_accuracy: 0.5516\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.1940 - accuracy: 0.5756 - val_loss: 1.2129 - val_accuracy: 0.5757\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.1297 - accuracy: 0.5997 - val_loss: 1.1779 - val_accuracy: 0.5804\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.0984 - accuracy: 0.6134 - val_loss: 1.1649 - val_accuracy: 0.5873\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.0486 - accuracy: 0.6290 - val_loss: 1.1691 - val_accuracy: 0.5867\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.0042 - accuracy: 0.6440 - val_loss: 1.1667 - val_accuracy: 0.5908\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.9870 - accuracy: 0.6499 - val_loss: 1.1461 - val_accuracy: 0.5982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZ2a0CrzqWfh",
        "outputId": "3557e326-1bbb-4229-ec73-a52784e3c43b"
      },
      "source": [
        "\"DEEPER REPEATED PATCHLESS MIXER\"\n",
        "num_classes = 10\n",
        "hidden_dim = 64\n",
        "n_repeat = 16\n",
        "depth = 4\n",
        "inputs = tf.keras.layers.Input(shape=(height, width, channels))\n",
        "reshaped = tf.keras.layers.Reshape([height, width * channels])(inputs)\n",
        "model = repeated_patchless_mixer(height, width * channels, hidden_dim, depth, num_classes, n_repeat)(reshaped)\n",
        "model = tf.keras.Model(inputs=inputs, outputs=model)\n",
        "print(model.summary())\n",
        "model.predict(train_images[:2, :, :])\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(train_images, train_labels, batch_size=64, epochs=10, \n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_138\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_164 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "reshape_152 (Reshape)        (None, 32, 96)            0         \n",
            "_________________________________________________________________\n",
            "model_137 (Functional)       (None, 10)                1295370   \n",
            "=================================================================\n",
            "Total params: 1,295,370\n",
            "Trainable params: 1,295,370\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f574ce8c7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 36s 38ms/step - loss: 1.8305 - accuracy: 0.3535 - val_loss: 1.5645 - val_accuracy: 0.4470\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 1.4588 - accuracy: 0.4841 - val_loss: 1.3692 - val_accuracy: 0.5135\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 1.3257 - accuracy: 0.5278 - val_loss: 1.3033 - val_accuracy: 0.5337\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 1.2209 - accuracy: 0.5701 - val_loss: 1.2239 - val_accuracy: 0.5600\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 1.1571 - accuracy: 0.5894 - val_loss: 1.1983 - val_accuracy: 0.5773\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 1.0874 - accuracy: 0.6156 - val_loss: 1.1703 - val_accuracy: 0.5879\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 1.0240 - accuracy: 0.6387 - val_loss: 1.1331 - val_accuracy: 0.5982\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 0.9677 - accuracy: 0.6563 - val_loss: 1.1369 - val_accuracy: 0.6030\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 0.9186 - accuracy: 0.6751 - val_loss: 1.1174 - val_accuracy: 0.6129\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 29s 37ms/step - loss: 0.8706 - accuracy: 0.6916 - val_loss: 1.1777 - val_accuracy: 0.6011\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfFdHWfDBJMp",
        "outputId": "66a28995-86d7-4bf1-b9c2-cbb0ad2faf29"
      },
      "source": [
        "height, width = 32, 32\n",
        "hidden_size = 512\n",
        "size = 16\n",
        "num_classes = 10\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(height, width, channels))\n",
        "reshaped = tf.keras.layers.Reshape([height, width * channels])(inputs)\n",
        "blender = blender_model(height, width * channels, hidden_size, size, num_classes)(reshaped)\n",
        "model = tf.keras.Model(inputs=inputs, outputs=blender)\n",
        "print(model.summary())\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(0.1, epsilon=0.1)\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, batch_size=64, epochs=10, \n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_89\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_106 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "reshape_100 (Reshape)        (None, 32, 96)            0         \n",
            "_________________________________________________________________\n",
            "model_88 (Functional)        (None, 10)                1081514   \n",
            "=================================================================\n",
            "Total params: 1,081,514\n",
            "Trainable params: 1,081,514\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 12s 14ms/step - loss: 1.9332 - accuracy: 0.2934 - val_loss: 1.5982 - val_accuracy: 0.4258\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 1.5638 - accuracy: 0.4408 - val_loss: 1.4949 - val_accuracy: 0.4674\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 1.4697 - accuracy: 0.4743 - val_loss: 1.4190 - val_accuracy: 0.4958\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 11s 13ms/step - loss: 1.4132 - accuracy: 0.4955 - val_loss: 1.4199 - val_accuracy: 0.4857\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 11s 13ms/step - loss: 1.3844 - accuracy: 0.5039 - val_loss: 1.3707 - val_accuracy: 0.5089\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 1.3521 - accuracy: 0.5144 - val_loss: 1.3857 - val_accuracy: 0.4999\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 1.3273 - accuracy: 0.5249 - val_loss: 1.3957 - val_accuracy: 0.5045\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 1.2987 - accuracy: 0.5347 - val_loss: 1.3739 - val_accuracy: 0.5112\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 1.2833 - accuracy: 0.5382 - val_loss: 1.3238 - val_accuracy: 0.5316\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 1.2727 - accuracy: 0.5439 - val_loss: 1.3481 - val_accuracy: 0.5201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "qoLv6V2dCxtA",
        "outputId": "c7124115-ab9f-4783-c110-4b36c1b32faa"
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 2s - loss: 1.2273 - accuracy: 0.5633\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpSV3rhzjJKk",
        "outputId": "6c7d10af-dc36-406a-cb67-9dc5de374c46"
      },
      "source": [
        "height, width, channels = train_images.shape[-3:]\n",
        "hidden_dim = 256\n",
        "depth = 16\n",
        "num_classes = 10\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(height, width, channels))\n",
        "reshaped = tf.keras.layers.Reshape([height, width * channels])(inputs)\n",
        "mixer = patchless_mixer(height, width * channels, hidden_dim, hidden_dim, depth, num_classes)(reshaped)\n",
        "model = tf.keras.Model(inputs=inputs, outputs=mixer)\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=10, \n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_97\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_114 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "reshape_108 (Reshape)        (None, 32, 96)            0         \n",
            "_________________________________________________________________\n",
            "model_96 (Functional)        (None, 10)                3285002   \n",
            "=================================================================\n",
            "Total params: 3,285,002\n",
            "Trainable params: 3,285,002\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 52s 33ms/step - loss: 1.8906 - accuracy: 0.3206 - val_loss: 1.4518 - val_accuracy: 0.4840\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 52s 33ms/step - loss: 1.4150 - accuracy: 0.4981 - val_loss: 1.3200 - val_accuracy: 0.5316\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 52s 33ms/step - loss: 1.2657 - accuracy: 0.5527 - val_loss: 1.2665 - val_accuracy: 0.5499\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 52s 33ms/step - loss: 1.1544 - accuracy: 0.5890 - val_loss: 1.1811 - val_accuracy: 0.5848\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 51s 33ms/step - loss: 1.0738 - accuracy: 0.6246 - val_loss: 1.1351 - val_accuracy: 0.6003\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 52s 33ms/step - loss: 0.9853 - accuracy: 0.6513 - val_loss: 1.1143 - val_accuracy: 0.6124\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 52s 33ms/step - loss: 0.9214 - accuracy: 0.6771 - val_loss: 1.1359 - val_accuracy: 0.6096\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 52s 33ms/step - loss: 0.8473 - accuracy: 0.7023 - val_loss: 1.1218 - val_accuracy: 0.6208\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 52s 33ms/step - loss: 0.7680 - accuracy: 0.7323 - val_loss: 1.1719 - val_accuracy: 0.6228\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 51s 33ms/step - loss: 0.6839 - accuracy: 0.7600 - val_loss: 1.2209 - val_accuracy: 0.6152\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "nYdxiEtusG4a",
        "outputId": "1f3b72bd-c79a-4a79-9f06-291c2df7aad0"
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 1s - loss: 1.1823 - accuracy: 0.6108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUIgCxUTydlf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}